{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Educe\n",
    "\n",
    "[Educe][educe] is a library for working with a variety of discourse corpora.\n",
    "This tutorial aims to show what using educe would be like when working with\n",
    "the [STAC][stac] corpus. \n",
    "\n",
    "We'll be working with a tiny fragment of the corpus included with educe.\n",
    "You may find it useful to symlink your larger copy from\n",
    "the STAC distribution and modify this tutorial accordingly.\n",
    "\n",
    "## Installation\n",
    "\n",
    "```shell\n",
    "git clone https://github.com/kowey/educe.git\n",
    "cd educe\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Note: these instructions assume you are running within\n",
    "a [virtual environment][virtualenv].\n",
    "If not, and if you have permission\n",
    "denied errors, replace `pip` with `sudo pip`.\n",
    "\n",
    "## Tutorial in browser (optional)\n",
    "\n",
    "This tutorial can either be followed along with the command line and your favourite\n",
    "text editor, or embedded in an interactive webpage via iPython:\n",
    "\n",
    "```shell\n",
    "pip install ipython\n",
    "cd tutorials\n",
    "ipython notebook\n",
    "```\n",
    "\n",
    "[stac]: http://www.irit.fr/STAC/\n",
    "[educe]: http://kowey.github.io/educe\n",
    "[virtualenv]: http://virtualenv.readthedocs.org/en/latest/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# some helper functions for the tutorial below\n",
    "\n",
    "def text_snippet(text):\n",
    "    \"short text fragment\"\n",
    "    if len(text) < 43:\n",
    "        return text\n",
    "    else:\n",
    "        return \"{0}...{1}\".format(text[:20], text[-20:])\n",
    "\n",
    "def highlight(astring, color=1):\n",
    "    \"coloured text\"\n",
    "    return(\"\\x1b[3{color}m{str}\\x1b[0m\".format(color=color, str=astring))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading corpus files (STAC)\n",
    "\n",
    "Typically, the first thing we want to do when working in educe is to read the corpus in.  This can be a bit slow, but as we will see later on, we can speed things up if we know what we're looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Slurping corpus dir [99/100]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[s1-league2-game1 [05] unannotated None]  199 : sabercat : anyone any clay? 200 : IG : nope\n",
      "[s1-league2-game1 [13] units hjoseph]  521 : sabercat : skinnylinny 522 : sabercat : som\n",
      "[s1-league2-game1 [10] units hjoseph]  393 : skinnylinny : Shall we extend? 394 : saberc\n",
      "[s1-league2-game1 [11] discourse hjoseph]  450 : skinnylinny : Argh 451 : skinnylinny : How \n",
      "[s1-league2-game1 [10] unannotated None]  393 : skinnylinny : Shall we extend? 394 : saberc\n",
      "[s1-league2-game1 [02] units lpetersen]  75 : sabercat : anyone has any wood? 76 : skinnyl\n",
      "[s1-league2-game1 [14] units SILVER]  577 : sabercat : skinny 578 : sabercat : I need 2\n",
      "[s1-league2-game3 [03] discourse lpetersen]  151 : amycharl : got wood anyone? 152 : sabercat \n",
      "[s1-league2-game1 [10] discourse hjoseph]  393 : skinnylinny : Shall we extend? 394 : saberc\n",
      "[s1-league2-game1 [12] units SILVER]  496 : sabercat : yes! 497 : sabercat : :D 498 : s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Slurping corpus dir [100/100 done]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import educe.stac\n",
    "\n",
    "# relative to the educe docs directory\n",
    "data_dir = '../data'\n",
    "corpus_dir = '{dd}/stac-sample'.format(dd=data_dir)\n",
    "\n",
    "# read everything from our sample\n",
    "reader = educe.stac.Reader(corpus_dir)\n",
    "corpus = reader.slurp(verbose=True)\n",
    "\n",
    "# print a text fragment from the first ten files we read\n",
    "for key in corpus.keys()[:10]:\n",
    "    doc = corpus[key]\n",
    "    print(\"[{0}] {1}\".format(key, doc.text()[:50]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faster reading\n",
    "\n",
    "If you know that you only want to work with a subset of the corpus files, you can pre-filter the corpus before reading the files. \n",
    "\n",
    "It helps to know here that an educe corpus is a mapping from [file id keys](https://educe.readthedocs.org/en/latest/api-doc/educe.html#educe.corpus.FileId) to Documents. The `FileId` tells us what makes a Document distinct from another:\n",
    "\n",
    "* document (eg. s1-league2-game1): in STAC, the game that was played (here, season 1, league 2, game 1)\n",
    "* subdocument (eg. 05): a mostly arbitrary subdivision of the documents motivated by technical constraints (overly large documents would cause our annotation tool to crash)\n",
    "* stage (eg. units, discourse, parsed): the kinds of annotations available in the document\n",
    "* annotator (eg. hjoseph): the main annotator for a document (gold standard documents have the distinguished annotators, BRONZE, SILVER, or GOLD)\n",
    "\n",
    "NB: unfortunately we have overloaded the word “document” here. When talking about file ids, “document” refers to a whole game.  But when talking about actual annotation objects an educe Document actually corresponds to a specific combination of document, subdocument, stage, and annotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Slurping corpus dir [11/12]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1-league2-game1 [01] units SILVER:  1 : sabercat : btw, are we playing without the ot\n",
      "s1-league2-game1 [01] discourse SILVER:  1 : sabercat : btw, are we playing without the ot\n",
      "s1-league2-game1 [02] discourse SILVER:  75 : sabercat : anyone has any wood? 76 : skinnyl\n",
      "s1-league2-game3 [01] discourse BRONZE:  1 : amycharl : i made it! 2 : amycharl : did the \n",
      "s1-league2-game1 [03] discourse SILVER:  109 : sabercat : well done! 110 : IG : More clay!\n",
      "s1-league2-game3 [02] units BRONZE:  73 : sabercat : skinny, got some ore? 74 : skinny\n",
      "s1-league2-game3 [01] units BRONZE:  1 : amycharl : i made it! 2 : amycharl : did the \n",
      "s1-league2-game1 [02] units SILVER:  75 : sabercat : anyone has any wood? 76 : skinnyl\n",
      "s1-league2-game3 [02] discourse BRONZE:  73 : sabercat : skinny, got some ore? 74 : skinny\n",
      "s1-league2-game1 [03] units SILVER:  109 : sabercat : well done! 110 : IG : More clay!\n",
      "s1-league2-game3 [03] discourse BRONZE:  151 : amycharl : got wood anyone? 152 : sabercat \n",
      "s1-league2-game3 [03] units BRONZE:  151 : amycharl : got wood anyone? 152 : sabercat \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Slurping corpus dir [12/12 done]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# nb: you can import this function from educe.stac.corpus\n",
    "def is_metal(fileid):  \n",
    "    \"is this a gold standard(ish) annotation file?\"\n",
    "    anno = fileid.annotator or \"\"\n",
    "    return anno.lower() in [\"bronze\", \"silver\", \"gold\"]\n",
    "    \n",
    "# pick out gold-standard documents\n",
    "subset = reader.filter(reader.files(), \n",
    "                       lambda k: is_metal(k) and int(k.subdoc) < 4)\n",
    "corpus_subset = reader.slurp(subset, verbose=True)\n",
    "for key in corpus_subset:\n",
    "    doc = corpus_subset[key]\n",
    "    print(\"{0}: {1}\".format(key, doc.text()[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1-league2-game3 [03] units BRONZE\n"
     ]
    }
   ],
   "source": [
    "from educe.corpus import FileId\n",
    "\n",
    "# pick out an example document to work with creating FileIds by hand\n",
    "# is not something we would typically do (normally we would just iterate\n",
    "# through a corpus), but it's useful for illustration\n",
    "ex_key = FileId(doc='s1-league2-game3',\n",
    "                subdoc='03',\n",
    "                stage='units',\n",
    "                annotator='BRONZE')\n",
    "ex_doc = corpus[ex_key]\n",
    "print(ex_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standing off\n",
    "\n",
    "Most annotations in the STAC corpus are [educe standoff annotations][standoff]. In educe terms, this means that they (perhaps indirectly) extend the `educe.annotation.Standoff` class and provide a `text_span()` function.  Much of our reasoning around annotations essentially consists of checking that their text spans overlap or enclose each other.\n",
    "\n",
    "As for the text spans, these refer to the raw text saved in files with an `.ac` extension (eg. `s1-league1-game3.ac`). In the [Glozz annotation tool][glozz], these `.ac` text files form a pair with their `.aa` xml counterparts.  Multiple annotation files can point to the same text file.\n",
    "\n",
    "There are also some annotations that come from 3rd party tools, which we will uncover later.\n",
    "\n",
    "[glozz]: http://www.glozz.org\n",
    "[standoff]: http://educe.readthedocs.org/en/latest/api-doc/educe.html#educe.annotation.Standoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Documents and EDUs\n",
    "\n",
    "A document is a sort of giant annotation that contains three other kinds of annotation\n",
    "\n",
    "* units - annotations that directly cover a span of text (EDUs, Resources, but also turns, dialogues)\n",
    "* relations - annotations that point from one annotation to another\n",
    "* schemas - annotations that point to a set of annotations\n",
    "\n",
    "To start things off, we'll focus on one type of unit-level annotation, the Elementary Discourse Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example units\n",
      "-------------\n",
      "(1,34)      stac_1368693094      [paragraph   ] 151 : amycharl : got wood anyone?\n",
      "(52,66)     stac_1368693099      [Accept      ] yep, for what?\n",
      "(117,123)   stac_1368693105      [Refusal     ] no way\n",
      "(189,191)   stac_1368693114      [Other       ] :)\n",
      "(209,210)   stac_1368693117      [Counteroffer] ?\n",
      "(659,668)   stac_1368693162      [Offer       ] how much?\n",
      "(22,26)     asoubeille_1374939590843 [Resource    ] wood\n",
      "(35,66)     stac_1368693098      [Turn        ] 152 : sabercat : yep, for what?\n",
      "(0,266)     stac_1368693124      [Dialogue    ]  151 : amycharl : go...cat : yep, thank you\n",
      "\n",
      "First few EDUs\n",
      "--------------\n",
      "(52,66)     stac_1368693099      [Accept      ] yep, for what?\n",
      "(117,123)   stac_1368693105      [Refusal     ] no way\n",
      "(163,171)   stac_1368693111      [Accept      ] could be\n",
      "(189,191)   stac_1368693114      [Other       ] :)\n"
     ]
    }
   ],
   "source": [
    "def preview_unit(doc, anno):\n",
    "    \"the default str(anno) can be a bit overwhelming\"\n",
    "    preview = \"{span: <11} {id: <20} [{type: <12}] {text}\"\n",
    "    text = doc.text(anno.text_span())\n",
    "    return preview.format(id=anno.local_id(),\n",
    "                          type=anno.type,\n",
    "                          span=anno.text_span(),\n",
    "                          text=text_snippet(text))\n",
    "\n",
    "print(\"Example units\")\n",
    "print(\"-------------\")\n",
    "seen = set()\n",
    "for anno in ex_doc.units:\n",
    "    if anno.type not in seen:\n",
    "        seen.add(anno.type)\n",
    "        print(preview_unit(ex_doc, anno))\n",
    "    \n",
    "print()\n",
    "print(\"First few EDUs\")\n",
    "print(\"--------------\")\n",
    "for anno in filter(educe.stac.is_edu, ex_doc.units)[:4]:\n",
    "    print(preview_unit(ex_doc, anno))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "# TODO\n",
    "\n",
    "Everything below this point should be considered to be in a scratch/broken state.\n",
    "It needs to ported over from its RST/DT considerations to STAC\n",
    "\n",
    "To do:\n",
    "\n",
    "* standing off (ac/aa) - shared aa\n",
    "* layers (units/discourse)\n",
    "* working with relations and schemas\n",
    "* grabbing resources etc (example of working with unit level annotation)\n",
    "* synchronising layers (grabbing the dialogue act and relations at the same time)\n",
    "* external annotations (postags, parse trees)\n",
    "* working with hypergraphs (implementing `_repr_png()_` would be pretty sweet)\n",
    "\n",
    "\n",
    "\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree searching\n",
    "\n",
    "The same span enclosure logic can be used to search parse trees for particular constituents, verb phrases. Alternatively, you can use the the `topdown` method provided by educe trees. This returns just the largest constituent for which some predicate is true.  It optionally accepts an additional argument to cut off the search when it is clearly out of bounds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we've explored a couple of basic educe concepts, which we hope will enable you to extract some data from your discourse corpora, namely\n",
    "\n",
    "* reading corpus data (and pre-filtering)\n",
    "* standoff annotations\n",
    "* searching by span enclosure, overlapping\n",
    "* working with trees\n",
    "* combining annotations from different sources\n",
    "\n",
    "The concepts above should transfer to whatever discourse corpus you are working with (that educe supports, or that you are prepared to supply a reader for).\n",
    "\n",
    "### Work in progress\n",
    "\n",
    "This tutorial is very much a work in progress (last update: 2014-09-19).\n",
    "Educe is a bit of a moving target, so [let me know](https://github.com/kowey/educe/issues) if you run into any trouble!\n",
    "\n",
    "### See also\n",
    "\n",
    "#### stac-util\n",
    "\n",
    "Some of the things you may want to do with the STAC corpus may already exist in the stac-util command line tool.\n",
    "stac-util is meant to be a sort of Swiss Army Knife, providing tools for editing the corpus. The query tools are more likely to be of interest:\n",
    "\n",
    "* text: display text and edu/dialogue segmentation in a friendly way\n",
    "* graph: draw discourse graphs with graphviz (arrows for relations, boxes for CDUs, etc)\n",
    "* filter-graph: visualise instances of relations (eg. Question answer pair)\n",
    "* count: generate statistics about the corpus\n",
    "\n",
    "See `stac-util --help` for more details.\n",
    "\n",
    "#### External tool support\n",
    "\n",
    "Educe has some support for reading data from outside the discourse corpus proper.  For example, if you run the stanford corenlp parser on the raw text, you can read them back into educe-style `ConstituencyTree` and `DependencyTree` annotations. See [educe.external](https://educe.readthedocs.org/en/latest/api-doc/educe.external.html) for details.\n",
    "\n",
    "If you have a part of speech tagger that you would like to use, the `educe.external.postag` module may be useful for representing the annotations that come out of it\n",
    "\n",
    "You can also add support for your own tools by creating annotations that extend `Standoff`, directly or otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
