{
 "metadata": {
  "name": "",
  "signature": "sha256:2fafb4f7481f7f3e513cf1b709735634d9c5502cd32c9780ca23f1ceb02cef27"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Educe\n",
      "\n",
      "[Educe][educe] is a library for working with a variety of discourse corpora.\n",
      "This tutorial aims to show what using educe would be like when working with\n",
      "the [Penn Discourse Treebank][pdtb] corpus. \n",
      "\n",
      "## Installation\n",
      "\n",
      "```shell\n",
      "git clone https://github.com/kowey/educe.git\n",
      "cd educe\n",
      "pip install -r requirements.txt\n",
      "```\n",
      "\n",
      "Note: these instructions assume you are running within\n",
      "a [virtual environment][virtualenv].\n",
      "If not, and if you have permission\n",
      "denied errors, replace `pip` with `sudo pip`.\n",
      "\n",
      "## Tutorial setup\n",
      "\n",
      "This tutorial require that you have a local copy of the PDTB. For purposes of this tutorial, you will need to link this into the data directory, for example\n",
      "\n",
      "```\n",
      "ln -s $HOME/CORPORA/pdtb_v2 data\n",
      "```\n",
      "\n",
      "Optionnally, to match the pdtb text spans to their analysis in the Penn Treebank, you need to \n",
      "have a local copy of the PTB at the same location \n",
      "\n",
      "\n",
      "```\n",
      "ln -s $HOME/CORPORA/PTBIII data\n",
      "```\n",
      "\n",
      "### Tutorial in browser (optional)\n",
      "\n",
      "This tutorial can either be followed along with the command line and your favourite\n",
      "text editor, or embedded in an interactive webpage via iPython:\n",
      "\n",
      "```shell\n",
      "pip install ipython\n",
      "cd tutorials\n",
      "ipython notebook\n",
      "```\n",
      "\n",
      "[pdtb]: http://www.seas.upenn.edu/~pdtb/\n",
      "[educe]: http://kowey.github.io/educe\n",
      "[virtualenv]: http://virtualenv.readthedocs.org/en/latest/\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Reading corpus files (PDTB)\n",
      "\n",
      "NB: unfortunately, at the time of this writing, PDTB support in educe is very much behind and rather inconsistent with that of the other corpora. Apologies for the mess!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "import educe.pdtb\n",
      "\n",
      "# relative to the educe docs directory\n",
      "data_dir = '../data'\n",
      "corpus_dir = '{dd}/pdtb_v2/data'.format(dd=data_dir)\n",
      "\n",
      "# read a small sample of the pdtb\n",
      "reader = educe.pdtb.Reader(corpus_dir)\n",
      "anno_files = reader.filter(reader.files(),\n",
      "                           lambda k: k.doc.startswith('wsj_231'))\n",
      "corpus = reader.slurp(anno_files, verbose=True)\n",
      "\n",
      "def stress(astring,color=1):\n",
      "    return(\"\\x1b[3%dm%s\\x1b[0m\"%(color,astring))\n",
      "     \n",
      "    \n",
      "def show_type(rel):\n",
      "    \"short string for a relation type\"\n",
      "    return type(rel).__name__[:-8]\n",
      "    \n",
      "# print the first five rel types we read from each doc\n",
      "for key in corpus.keys()[:10]:\n",
      "    doc = corpus[key]\n",
      "    rtypes = [show_type(r) for r in doc]\n",
      "    print(\"[{0}] {1}\".format(key.doc, \" \".join(rtypes[:5])))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "Slurping corpus dir [0/8]\r",
        "Slurping corpus dir [1/8]\r",
        "Slurping corpus dir [2/8]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "Slurping corpus dir [3/8]\r",
        "Slurping corpus dir [4/8]\r",
        "Slurping corpus dir [5/8]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[wsj_2313] Entity Explicit Explicit Implicit Explicit\n",
        "[wsj_2316] Explicit Implicit Implicit Implicit Explicit\n",
        "[wsj_2311] Implicit\n",
        "[wsj_2310] Entity\n",
        "[wsj_2315] Explicit Implicit Entity Explicit Implicit\n",
        "[wsj_2314] Explicit Explicit Implicit Explicit Entity\n",
        "[wsj_2317] Implicit Implicit Explicit Implicit Explicit\n",
        "[wsj_2319] Explicit\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "Slurping corpus dir [6/8]\r",
        "Slurping corpus dir [7/8]\r",
        "Slurping corpus dir [8/8 done]\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "corpus.keys()[0].__dict__.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "['doc', 'subdoc', 'annotator', 'stage']"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(corpus.keys()[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "wsj_2313 [None] discourse None\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lr = [r for r in doc]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r0 = lr[0]\n",
      "type(r0).__name__"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "'ExplicitRelation'"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def display_rel(r):\n",
      "    if show_type(r)==\"Explicit\":\n",
      "        conn = stress(r.connhead)\n",
      "    else:\n",
      "        conn = stress(\"Implicit\"+str(r.connective1))  \n",
      "    return(\"%s \\n \\t ---[%s]----> \\n \\t\\t\\t%s\"%(stress(r.arg1.text,2),conn,stress(r.arg2.text,2)))\n",
      "        \n",
      "\n",
      "print(display_rel(r0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\u001b[32mto purchase Quest stock at a discount\u001b[0m \n",
        " \t ---[\u001b[31mConnective(if | Contingency.Condition.Hypothetical)\u001b[0m]----> \n",
        " \t\t\t\u001b[32many person or group acquires more than 15% of the company's common stock or announces a tender offer\u001b[0m\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "r0.connhead.text"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "u'if'"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Gorn addresses"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print the first seven gorn addresses for the first argument of the first\n",
      "# 5 rels we read from each doc\n",
      "for key in corpus.keys()[:3]:\n",
      "    doc = corpus[key]\n",
      "    rels = doc[:5]\n",
      "    print(key.doc)\n",
      "    for r in doc[:5]:\n",
      "        print(\"\\t{0}\".format(r.arg1.gorn[:7]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "wsj_2313\n",
        "\t[1]\n",
        "\t[3.0]\n",
        "\t[4.0.0]\n",
        "\t[5]\n",
        "\t[6.0.0, 6.0.1, 6.0.2, 6.0.3]\n",
        "wsj_2316\n",
        "\t[0.0.0, 0.0.1, 0.0.3, 0.1, 0.2]\n",
        "\t[2.0.0, 2.0.1, 2.0.3, 2.1, 2.2]\n",
        "\t[4]\n",
        "\t[5.3.4.1.1.2.2.2]\n",
        "\t[5.3.4]\n",
        "wsj_2311\n",
        "\t[0]\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Penn Treebank integration"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from educe.pdtb import ptb\n",
      "\n",
      "# confusingly, this is not an educe corpus reader, but the NLTK\n",
      "# bracketed reader.  Sorry\n",
      "ptb_reader = ptb.reader('{dd}/PTBIII/parsed/mrg/wsj/'.format(dd=data_dir))\n",
      "ptb_trees = {}\n",
      "for key in corpus.keys()[:3]:\n",
      "    ptb_trees[key] = ptb.parse_trees(corpus, key, ptb_reader)\n",
      "    print(\"{0}...\".format(str(ptb_trees[key])[:100]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ImportError",
       "evalue": "cannot import name ptb",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-9-73cd8ac5d09b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0meduce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpdtb\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mptb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# confusingly, this is not an educe corpus reader, but the NLTK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# bracketed reader.  Sorry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mptb_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mptb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{dd}/PTBIII/parsed/mrg/wsj/'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mImportError\u001b[0m: cannot import name ptb"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls ../data/PTBIII/parsed/mrg/wsj/"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def pick_subtree(tree, gparts):\n",
      "    if gparts:\n",
      "        return pick_subtree(tree[gparts[0]], gparts[1:])\n",
      "    else:\n",
      "        return tree\n",
      "\n",
      "# print the first seven gorn addresses for the first argument of the first\n",
      "# 5 rels we read from each doc, along with the corresponding subtree\n",
      "ndocs = 1\n",
      "nrels = 3\n",
      "ngorn = -1\n",
      "\n",
      "for key in corpus.keys()[:1]:\n",
      "    doc = corpus[key]\n",
      "    rels = doc[:nrels]\n",
      "    ptb_tree = ptb_trees[key]\n",
      "    print(\"=======\"+key.doc)\n",
      "    for i,r in enumerate(doc[:nrels]):\n",
      "        print(\"---- relation %d\"%(i+1))\n",
      "        print(display_rel(r))\n",
      "        \n",
      "        for (i,arg) in enumerate([r.arg1,r.arg2]):\n",
      "            print(\".... arg %s:\"%(i+1))\n",
      "            glist = arg.gorn # arg.gorn[:ngorn]\n",
      "            subtrees = [pick_subtree(ptb_tree, g.parts) for g in glist]\n",
      "            for gorn, subtree in zip(glist, subtrees):\n",
      "                print(\"{0}\\n{1}\".format(gorn, str(subtree)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(subtree.flatten())\n",
      "print(subtree.leaves())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from copy import copy\n",
      "t = copy(subtree)\n",
      "print(\"constituent = \"+stress(t.node))\n",
      "for i in range(len(subtree)):\n",
      "    print(i)\n",
      "    print(t.pop())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from copy import copy\n",
      "t = copy(subtree)\n",
      "\n",
      "def expand(subtree):\n",
      "    if type(subtree) is unicode:\n",
      "        print(subtree)\n",
      "    else:\n",
      "        print(\"constituent = \"+stress(subtree.node))\n",
      "        for i,st in enumerate(subtree):\n",
      "            #print(i)\n",
      "            expand(st)\n",
      "  \n",
      "expand(t)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Work in progress\n",
      "\n",
      "This tutorial is very much a work in progress.\n",
      "Moreover, support for the PDTB in educe is still very incomplete.\n",
      "So it's very much a moving target. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}